{"meta":{"title":"eshenhu's blog","subtitle":null,"description":"It never be later than do nothing","author":"eshenhu","url":"https://eshenhu.github.io"},"pages":[],"posts":[{"title":"system test thoughts","slug":"System-test-thoughts","date":"2017-08-16T15:33:10.000Z","updated":"2017-10-16T15:45:40.000Z","comments":true,"path":"2017/08/16/System-test-thoughts/","link":"","permalink":"https://eshenhu.github.io/2017/08/16/System-test-thoughts/","excerpt":"谈谈如何有效的测量系统负载和响应嵌入式系统在系统测试过程中往往需要进行 Stability, Robustness, Accessbility, Responsibility 等等系统测试. 以来保证系统的功能完整性和健壮性. 嵌入式系统在设计在立项阶段会给出一个设计目标, 比如一款路由器，往往会给出以下类似的要求: 支持 802.11n/g/a/b 支持. 支持 2.4G, 5G 双频. 最大速率支持 (450Mbps). … 作为系统设计者,需要在设计阶段锚定这些目标进行技术选型. 如果当前有类似产品设计经验, 可以借鉴之前的经验进行选型. 如果是第一次设计, 保守的做法便是借鉴其他厂商的方案, 等待自己对系统了解的加深和经验的丰富再进行下一阶段的开发. 无论以什么方式开局, 一个 ·能用· ·易用· ·好用· 的测试环境是必须要在第一时间阶段准备, 才能应对产品开发阶段的各项挑战. 结合我手中的几个项目, 想谈谈自己的一点关于系统测试的看法.","text":"谈谈如何有效的测量系统负载和响应嵌入式系统在系统测试过程中往往需要进行 Stability, Robustness, Accessbility, Responsibility 等等系统测试. 以来保证系统的功能完整性和健壮性. 嵌入式系统在设计在立项阶段会给出一个设计目标, 比如一款路由器，往往会给出以下类似的要求: 支持 802.11n/g/a/b 支持. 支持 2.4G, 5G 双频. 最大速率支持 (450Mbps). … 作为系统设计者,需要在设计阶段锚定这些目标进行技术选型. 如果当前有类似产品设计经验, 可以借鉴之前的经验进行选型. 如果是第一次设计, 保守的做法便是借鉴其他厂商的方案, 等待自己对系统了解的加深和经验的丰富再进行下一阶段的开发. 无论以什么方式开局, 一个 ·能用· ·易用· ·好用· 的测试环境是必须要在第一时间阶段准备, 才能应对产品开发阶段的各项挑战. 结合我手中的几个项目, 想谈谈自己的一点关于系统测试的看法. XXX 4G 路由器 此产品是利用有线宽带做接入网络,使用4G信号进行无线传输的无线设备. 设备立项阶段的设计目标为: 最大支持32用户. 上下行最高速率支持150Mbps. 支持IpSec传输. 支持Cwmp集中管理以及本地管理. 支持自开站和自优化功能. 此项目是在之前已有的平台移植进行二次开发,成立之初就发现之前单元/系统测试的极大问题. 主要暴漏在: 版本迭代过程中没有良好的回归测试覆盖. 历史版本中大量出现解决一个问题又引入新问题的commit. 系统测试没有自动化实践. 完全是靠人力进行弥补, 导致产品开发周期变长, 解决问题回溯历史时间很长. 有关系统测试的概念不清, 只关注功能实现而忽略了系统的性能. 这里只对最后一项进行一些实践说明,怎么才能提高产品的系统性能. 之前产品有系统负载的测量, 主要关注在某个系统模拟负载情况下的CPU/MEMORY的性能. 但是没有对系统的整体性能进行测量. 为什么？ 系统是一个软实时的设备,每个TTI(1ms)进行用户的调度,如果没有及时调度用户,会发生速率变低, 对时延敏感的响应降低. 所以需要在系统测试中加入不同模拟负载下用户的调度响应时间. CPU 的利用率仅仅描述了CPU一段时间的繁忙程度, 不能够反映系统的响应. 所以需要对实时的进程进行测量, 比如当前设备运行 的 MAC, PHY 实体都是对实时性要求最高的功能实体, 需要对两者之间消息处理的时间进行监控. 从用户角度出发, 需要监控从尝试接入到接入成功的时间响应, 此时间可以从另外一个维度进行系统的性能测量. 问题发现PHY STOP使用iPerf进行速率测试业务过程中,32UE情况下偶然会出现PHY STOP. 原因MAC-PHY之间有3 TTI为时间窗口作为缓冲, 如果在 3ms 之内能够同步成功, 消息既可以满足要求. 如果某个时刻未能满足这个需求, 短时间内会造成速率下降, 长时间就会出现不同步现象 PHY 就会自动 STOP. 分析使用 ftrace 分析sche info发现, MAC进程会被 IO 切换, 查看分析文件发现, MAC某处使用syslog 打印信息, syslog 默认使用本地514端口做UDP报文, 一旦超过 系统 max_tranmit_message 的容量限制, 便会成为阻塞操作, 等待 syslogd 处理消息完毕. 但是syslogd 优先级为 20的正常优先级, 即为还没有处理完socket 的内容就立刻被抢占, 导致MAC吞吐率下降. 后改为自定义的日志处理系统, 可以改善这个情况. 测试跟进CII增加MAC-PHY消息处理响应,每周版本做跟踪处理. IpSec 影响IpSec 开启后系统性能下降严重. 现象IpSec 启用后系统性能对比未使用是无论是吞吐量还是响应时间都有很大的degradation. 原因根据ftrace 打点分析, 在ipsec 同步加密数据阶段, 消耗了太多的cpu cycle. 使得系统负载升高. 解决使用硬件提供的协处理器进行硬件加解密功能, 降低CPU使用率. 使用 zero-copy 框架进行进一步优化. 测试跟进对报文在各功能实体模块之间进行打点记录,每周的系统测试记录详细数据.","categories":[],"tags":[]},{"title":"Some thoughts about memory issue","slug":"Some-thoughts-about-memory-issue","date":"2017-06-26T14:27:24.000Z","updated":"2017-06-26T15:43:14.000Z","comments":true,"path":"2017/06/26/Some-thoughts-about-memory-issue/","link":"","permalink":"https://eshenhu.github.io/2017/06/26/Some-thoughts-about-memory-issue/","excerpt":"最近一段时间在忙于内存问题的事情，算是有些成果输出吧。借机谈论一下自己的感想。 近来工程团队遇到几次比较严重的内存泄漏问题,有一些问题无疾而终.在接手工作后发现这些问题均是发生在客户的现场,很难在实验室复现. 即使能够在长时间stability测试发现问题，因为现场发生比较遥远，也是很难去定位问题. 针对此类问题,团队近期输出了几个内部产品, 较好的解决了其中的一些问题。","text":"最近一段时间在忙于内存问题的事情，算是有些成果输出吧。借机谈论一下自己的感想。 近来工程团队遇到几次比较严重的内存泄漏问题,有一些问题无疾而终.在接手工作后发现这些问题均是发生在客户的现场,很难在实验室复现. 即使能够在长时间stability测试发现问题，因为现场发生比较遥远，也是很难去定位问题. 针对此类问题,团队近期输出了几个内部产品, 较好的解决了其中的一些问题。 项目团队在 Devops team 的协助下已经有一套比较完备的测试工具, 单元测试，valgrind内存检查.但是在集成测试阶段还是缺乏手段去快速定位内存问题。针对此类问题 工程团队重构了自定义的内存分配器，加入了头尾两部分的magic number, FREE() 内存后reset内存单元内容. 在每次 ALLOC()/FREE() 强制检查合法性, 第一时间保留现场. 针对 wild pointer visit 的棘手问题的时候, 工程团队兵分两路. 一路从现有的集成测试出发，使用valgrind工具编译代码直接进入集成测试阶段进行验证.针对实时性很强的部分进行stub处理.另外一路，从系统角度，引入 dynamic memory check. 大致原理是binding 一个实时性可以调整的background线程, 使用kernel调度进行实时性内存检查, 一旦发生内存越界 magic number override 情况立刻报告. 实时性视内存问题严重性选择可调. 统计内存泄漏问题，输出了一个增强功能，主要是在内存分配阶段增加extra struct 到历史容器存储. 添加FUNCTION, LINENUMBER, 方便定位问题. 集成测试采用震荡的方式进行用例测试，放大内存泄漏问题. 使用 snapshot 功能定制差异比较. 和Devops团队合作把内存检查当作必要测试添加到robust测试用例当中. 通过工程团队的一段时间的持续改进,一些问题在后续的解决过程中得到效率的提升.","categories":[],"tags":[]},{"title":"Efficient data transfer through zero copy","slug":"Efficient-data-transfer-through-zero-copy","date":"2017-06-04T16:21:11.000Z","updated":"2017-06-11T02:43:16.000Z","comments":true,"path":"2017/06/05/Efficient-data-transfer-through-zero-copy/","link":"","permalink":"https://eshenhu.github.io/2017/06/05/Efficient-data-transfer-through-zero-copy/","excerpt":"Zero-copy I/O practice in projectRecently weeks, I was working on how to exploit the potentialities with the GMAC(1G Ethernet Media Access Controller) on the SoC in my desktop. This SoC was used in the telecommunication field which provide the fast-transfer-data capability with some interesting MAC features. In this article, I had like share some experiences on how to utilize this MAC achieving better network throughput during this work. Preface@[Blog] The following articles were worth having a look before going forward. Zero Copy I: User-Mode Perspective (from Linux Journal, strongly recommended to read) An Efficient Zero-Copy I/O Framework for UNIX (most of thoughts comes from here)","text":"Zero-copy I/O practice in projectRecently weeks, I was working on how to exploit the potentialities with the GMAC(1G Ethernet Media Access Controller) on the SoC in my desktop. This SoC was used in the telecommunication field which provide the fast-transfer-data capability with some interesting MAC features. In this article, I had like share some experiences on how to utilize this MAC achieving better network throughput during this work. Preface@[Blog] The following articles were worth having a look before going forward. Zero Copy I: User-Mode Perspective (from Linux Journal, strongly recommended to read) An Efficient Zero-Copy I/O Framework for UNIX (most of thoughts comes from here) After reading these articles, then you will know how the Java.nio.channels works. If you have more time, you can dig more on the Kafaka, the most popular message queue framework written by LinkedIn. So, let’s first look at the capability of PHY/MAC in my hand. The PHY was provided by Atheros AR8031 as Ethernet transceiver and Atheros AR8327 as Ethernet switch. Compatible with IEEE Standard 802.3. Full duplex operation 1000 Mbps operation speeds. Statistics counter registers for RMON/MIB. Embedded DMA. Only for SGMII: Integrated Physical Coding Sub-layer (PCS) with auto-negotiation. MDIO interface provided to control external phys from the Embedded RISC processor. Automatic pad and cyclic redundancy check (CRC) generation on transmitted frames. Automatic discard of frames received with errors. Receive and transmit IP, TCP and UDP checksum offload. Both IPv4 and IPv6 packet types supported. Address checking logic for four specific 48-bit addresses, four types of Ids, promiscuous mode, externaladdress checking, hash matching for unicast and multicast destination addresses and Wake-on-LAN. Programmable IPG stretch. Support for 802.1Q VLAN tagging with recognition of incoming VLAN and priority tagged frames. Support for 802.1Qbb priority-based flow control – PFC Negotiation mode. Full utilization of the Tx 1 Gbps line. Provides sufficient buffer 16KB to support lossless reception of maximum length (jumbo-type) up to 10,240Bytes Ethernet frames. For RGMII only: RGMII electrical characteristics compliant with RGMII v1.3 (thus based upon 2.5V CMOS interface voltages as defined by JEDEC EIA/JESD8-5), and are not compliant with RGMII v2.0. Support for 1588 V1/V2. Support for 802.3az Energy Efficient Ethernet Some advanced features which attract on me were: Statistics counter registers for RMON/MIB. (then we can get performance comparison on the MAC level, great feature.) Programmable IPG stretch. Checksum offload. Automatic padding and CRC generation. 10KB buffer! Sctter-Gather capability! Do itIn this embedded project, it was not allowed 3rd organization/person install/uninstall any package without authorization, which was guaranteed by the Trust Zone Area, it means any installed package after HASH self-signed must be verified by the public key install on this area, otherwise it will failed to get install or upgrade. What I want to said was - we trust the software installed on the board. Then it means we don’t need to consider the security issues mentioned in the 2nd article. Then we can simplify our design without considering security. Some highlight feature include: Direct linear address mapping (vir2phy, phy2vir). support more than one page size space. Zero-copy from filling the message in user space to sending message into the device in kernel space. (This GMAC support scatter-gather functionality , and the kernel later than 2.6.xx support the scatter-gather functionality) Public API to application in user space, another public API to device driver in kernel module. It provide a simple memory cache scheme in user space level, decreasing the system trap call on most circumstances. as well as it will re-fill/request to the memory pool if the threshold reached, one system call was happened only till this time. It expose more detailed real-time information in /proc file-system. Some aspects need to consider in front of project are: Memory access time is unpredictable. Memory bandwidth is limited. Data change between application is very high. Lifetime of exchanging data was short. (get/put) Linux use page table translation to get better protection, which means it was not so straightforward to access memory. Other hardware limitation, (System BUS bandwidth, MAC interface). These limitations/requirements decide the way what we do. In purpose of better memory management between kernel space and user space, we setup a raw virtual device with fixed I/O start address and length when start kernel, then both user space application which can use mmap() mapping the I/O space to its own virtual address and kernel module can access the same memory address via the fixed offset. There are some inherent access attributes on those memory, so it is necessary to have a test on which cache scheme was best suit for our requirement. For achieve the best system efficiency: Use L1-only cached memory. Zero-copy whenever possible. Minimize number of system calls and context switch. So, let’s have a look at this picture show: Design detailsEndActually, in our products, other module/process also use this POOL as hot-fast data storage, such like we develop the fsyslog which was an log framework providing the functions like syslogd(…) in Unix but it provide shared-memory based logging scheme with faster and non-blocking operation when logging in user application, etc. Later I will show the comparison after this changes, which achieving more than 30% throughput boost in whole and 2% load decrease in our specified product.","categories":[],"tags":[]},{"title":"don't use memset() init your struct","slug":"don-t-use-memset-init-your-struct","date":"2017-06-04T14:17:59.000Z","updated":"2017-06-04T15:58:53.000Z","comments":true,"path":"2017/06/04/don-t-use-memset-init-your-struct/","link":"","permalink":"https://eshenhu.github.io/2017/06/04/don-t-use-memset-init-your-struct/","excerpt":"Don’t use memset init your structEven in some open source project, we always see memset filled in the code, here I had like give the reason why we should not use memset if possible.","text":"Don’t use memset init your structEven in some open source project, we always see memset filled in the code, here I had like give the reason why we should not use memset if possible. memset was subject to give side-effect to your code.memset descriptionIn some projects, memset was used to flush the struct,like the example given here bind example given in die.net 123456789int main(int argc, char *argv[])&#123; int sfd, cfd; struct sockaddr_un my_addr, peer_addr; ... memset(&amp;my_addr, 0, sizeof(struct sockaddr_un)); /* Clear structure */ ...&#125; memset will flush with byte by byte in your raw memory. in such situations, only 0 or possible 0xFF was allowed, otherwise you will get some results more than what you expected.Some examples like this one: good example memset was not efficient than the other solution.memset will have one function call when use it.I will take this struct as example: Disassemble code on the x86-64 arch machine. how we handle this with more elegant manner?Use initlization! 1struct sockaddr_un myaddr = &#123;&#125;; Have a look at the disassemble code: Oops, it just use less code to finish this flush operation! Don’t use memset anymore!","categories":[],"tags":[{"name":"Language","slug":"Language","permalink":"https://eshenhu.github.io/tags/Language/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-06-04T04:27:23.000Z","updated":"2017-06-04T04:27:23.000Z","comments":true,"path":"2017/06/04/hello-world/","link":"","permalink":"https://eshenhu.github.io/2017/06/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}