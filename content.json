{"meta":{"title":"eshenhu's blog","subtitle":null,"description":"It never be later than do nothing","author":"eshenhu","url":"https://eshenhu.github.io"},"pages":[],"posts":[{"title":"Some thoughts about memory issue","slug":"Some-thoughts-about-memory-issue","date":"2017-06-26T14:27:24.000Z","updated":"2017-06-26T15:43:14.000Z","comments":true,"path":"2017/06/26/Some-thoughts-about-memory-issue/","link":"","permalink":"https://eshenhu.github.io/2017/06/26/Some-thoughts-about-memory-issue/","excerpt":"最近一段时间在忙于内存问题的事情，算是有些成果输出吧。借机谈论一下自己的感想。 近来工程团队遇到几次比较严重的内存泄漏问题,有一些问题无疾而终.在接手工作后发现这些问题均是发生在客户的现场,很难在实验室复现. 即使能够在长时间stability测试发现问题，因为现场发生比较遥远，也是很难去定位问题. 针对此类问题,团队近期输出了几个内部产品, 较好的解决了其中的一些问题。","text":"最近一段时间在忙于内存问题的事情，算是有些成果输出吧。借机谈论一下自己的感想。 近来工程团队遇到几次比较严重的内存泄漏问题,有一些问题无疾而终.在接手工作后发现这些问题均是发生在客户的现场,很难在实验室复现. 即使能够在长时间stability测试发现问题，因为现场发生比较遥远，也是很难去定位问题. 针对此类问题,团队近期输出了几个内部产品, 较好的解决了其中的一些问题。 项目团队在 Devops team 的协助下已经有一套比较完备的测试工具, 单元测试，valgrind内存检查.但是在集成测试阶段还是缺乏手段去快速定位内存问题。针对此类问题 工程团队重构了自定义的内存分配器，加入了头尾两部分的magic number, FREE() 内存后reset内存单元内容. 在每次 ALLOC()/FREE() 强制检查合法性, 第一时间保留现场. 针对 wild pointer visit 的棘手问题的时候, 工程团队兵分两路. 一路从现有的集成测试出发，使用valgrind工具编译代码直接进入集成测试阶段进行验证.针对实时性很强的部分进行stub处理.另外一路，从系统角度，引入 dynamic memory check. 大致原理是binding 一个实时性可以调整的background线程, 使用kernel调度进行实时性内存检查, 一旦发生内存越界 magic number override 情况立刻报告. 实时性视内存问题严重性选择可调. 统计内存泄漏问题，输出了一个增强功能，主要是在内存分配阶段增加extra struct 到历史容器存储. 添加FUNCTION, LINENUMBER, 方便定位问题. 集成测试采用震荡的方式进行用例测试，放大内存泄漏问题. 使用 snapshot 功能定制差异比较. 和Devops团队合作把内存检查当作必要测试添加到robust测试用例当中. 通过工程团队的一段时间的持续改进,一些问题在后续的解决过程中得到效率的提升.","categories":[],"tags":[]},{"title":"Efficient data transfer through zero copy","slug":"Efficient-data-transfer-through-zero-copy","date":"2017-06-04T16:21:11.000Z","updated":"2017-06-11T02:43:16.000Z","comments":true,"path":"2017/06/05/Efficient-data-transfer-through-zero-copy/","link":"","permalink":"https://eshenhu.github.io/2017/06/05/Efficient-data-transfer-through-zero-copy/","excerpt":"Zero-copy I/O practice in projectRecently weeks, I was working on how to exploit the potentialities with the GMAC(1G Ethernet Media Access Controller) on the SoC in my desktop. This SoC was used in the telecommunication field which provide the fast-transfer-data capability with some interesting MAC features. In this article, I had like share some experiences on how to utilize this MAC achieving better network throughput during this work. Preface@[Blog] The following articles were worth having a look before going forward. Zero Copy I: User-Mode Perspective (from Linux Journal, strongly recommended to read) An Efficient Zero-Copy I/O Framework for UNIX (most of thoughts comes from here)","text":"Zero-copy I/O practice in projectRecently weeks, I was working on how to exploit the potentialities with the GMAC(1G Ethernet Media Access Controller) on the SoC in my desktop. This SoC was used in the telecommunication field which provide the fast-transfer-data capability with some interesting MAC features. In this article, I had like share some experiences on how to utilize this MAC achieving better network throughput during this work. Preface@[Blog] The following articles were worth having a look before going forward. Zero Copy I: User-Mode Perspective (from Linux Journal, strongly recommended to read) An Efficient Zero-Copy I/O Framework for UNIX (most of thoughts comes from here) After reading these articles, then you will know how the Java.nio.channels works. If you have more time, you can dig more on the Kafaka, the most popular message queue framework written by LinkedIn. So, let’s first look at the capability of PHY/MAC in my hand. The PHY was provided by Atheros AR8031 as Ethernet transceiver and Atheros AR8327 as Ethernet switch. Compatible with IEEE Standard 802.3. Full duplex operation 1000 Mbps operation speeds. Statistics counter registers for RMON/MIB. Embedded DMA. Only for SGMII: Integrated Physical Coding Sub-layer (PCS) with auto-negotiation. MDIO interface provided to control external phys from the Embedded RISC processor. Automatic pad and cyclic redundancy check (CRC) generation on transmitted frames. Automatic discard of frames received with errors. Receive and transmit IP, TCP and UDP checksum offload. Both IPv4 and IPv6 packet types supported. Address checking logic for four specific 48-bit addresses, four types of Ids, promiscuous mode, externaladdress checking, hash matching for unicast and multicast destination addresses and Wake-on-LAN. Programmable IPG stretch. Support for 802.1Q VLAN tagging with recognition of incoming VLAN and priority tagged frames. Support for 802.1Qbb priority-based flow control – PFC Negotiation mode. Full utilization of the Tx 1 Gbps line. Provides sufficient buffer 16KB to support lossless reception of maximum length (jumbo-type) up to 10,240Bytes Ethernet frames. For RGMII only: RGMII electrical characteristics compliant with RGMII v1.3 (thus based upon 2.5V CMOS interface voltages as defined by JEDEC EIA/JESD8-5), and are not compliant with RGMII v2.0. Support for 1588 V1/V2. Support for 802.3az Energy Efficient Ethernet Some advanced features which attract on me were: Statistics counter registers for RMON/MIB. (then we can get performance comparison on the MAC level, great feature.) Programmable IPG stretch. Checksum offload. Automatic padding and CRC generation. 10KB buffer! Sctter-Gather capability! Do itIn this embedded project, it was not allowed 3rd organization/person install/uninstall any package without authorization, which was guaranteed by the Trust Zone Area, it means any installed package after HASH self-signed must be verified by the public key install on this area, otherwise it will failed to get install or upgrade. What I want to said was - we trust the software installed on the board. Then it means we don’t need to consider the security issues mentioned in the 2nd article. Then we can simplify our design without considering security. Some highlight feature include: Direct linear address mapping (vir2phy, phy2vir). support more than one page size space. Zero-copy from filling the message in user space to sending message into the device in kernel space. (This GMAC support scatter-gather functionality , and the kernel later than 2.6.xx support the scatter-gather functionality) Public API to application in user space, another public API to device driver in kernel module. It provide a simple memory cache scheme in user space level, decreasing the system trap call on most circumstances. as well as it will re-fill/request to the memory pool if the threshold reached, one system call was happened only till this time. It expose more detailed real-time information in /proc file-system. Some aspects need to consider in front of project are: Memory access time is unpredictable. Memory bandwidth is limited. Data change between application is very high. Lifetime of exchanging data was short. (get/put) Linux use page table translation to get better protection, which means it was not so straightforward to access memory. Other hardware limitation, (System BUS bandwidth, MAC interface). These limitations/requirements decide the way what we do. In purpose of better memory management between kernel space and user space, we setup a raw virtual device with fixed I/O start address and length when start kernel, then both user space application which can use mmap() mapping the I/O space to its own virtual address and kernel module can access the same memory address via the fixed offset. There are some inherent access attributes on those memory, so it is necessary to have a test on which cache scheme was best suit for our requirement. For achieve the best system efficiency: Use L1-only cached memory. Zero-copy whenever possible. Minimize number of system calls and context switch. So, let’s have a look at this picture show: Design detailsEndActually, in our products, other module/process also use this POOL as hot-fast data storage, such like we develop the fsyslog which was an log framework providing the functions like syslogd(…) in Unix but it provide shared-memory based logging scheme with faster and non-blocking operation when logging in user application, etc. Later I will show the comparison after this changes, which achieving more than 30% throughput boost in whole and 2% load decrease in our specified product.","categories":[],"tags":[]},{"title":"don't use memset() init your struct","slug":"don-t-use-memset-init-your-struct","date":"2017-06-04T14:17:59.000Z","updated":"2017-06-04T15:58:53.000Z","comments":true,"path":"2017/06/04/don-t-use-memset-init-your-struct/","link":"","permalink":"https://eshenhu.github.io/2017/06/04/don-t-use-memset-init-your-struct/","excerpt":"Don’t use memset init your structEven in some open source project, we always see memset filled in the code, here I had like give the reason why we should not use memset if possible.","text":"Don’t use memset init your structEven in some open source project, we always see memset filled in the code, here I had like give the reason why we should not use memset if possible. memset was subject to give side-effect to your code.memset descriptionIn some projects, memset was used to flush the struct,like the example given here bind example given in die.net 123456789int main(int argc, char *argv[])&#123; int sfd, cfd; struct sockaddr_un my_addr, peer_addr; ... memset(&amp;my_addr, 0, sizeof(struct sockaddr_un)); /* Clear structure */ ...&#125; memset will flush with byte by byte in your raw memory. in such situations, only 0 or possible 0xFF was allowed, otherwise you will get some results more than what you expected.Some examples like this one: good example memset was not efficient than the other solution.memset will have one function call when use it.I will take this struct as example: Disassemble code on the x86-64 arch machine. how we handle this with more elegant manner?Use initlization! 1struct sockaddr_un myaddr = &#123;&#125;; Have a look at the disassemble code: Oops, it just use less code to finish this flush operation! Don’t use memset anymore!","categories":[],"tags":[{"name":"Language","slug":"Language","permalink":"https://eshenhu.github.io/tags/Language/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-06-04T04:27:23.000Z","updated":"2017-06-04T04:27:23.000Z","comments":true,"path":"2017/06/04/hello-world/","link":"","permalink":"https://eshenhu.github.io/2017/06/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}